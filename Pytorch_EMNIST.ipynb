{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_EMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBgTKkcZ5bAONahGtkAK5Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f9add1a4c67c4ce78cf68c86a11f9a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b2190d9534844081b7d920eaee37eb29",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8228553e040145ecb99e77684c81fbc0",
              "IPY_MODEL_ac0d23690ea640d1b09901e60e0e9e46"
            ]
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UrmilaAirsang/Pytorch/blob/main/Pytorch_EMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq_yx5DH9_ei"
      },
      "source": [
        "Pipeline for DNN\r\n",
        "1. Prepare the data\r\n",
        "2. Build the model\r\n",
        "3. Train the model\r\n",
        "4. Analyze the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu_wegdl943K"
      },
      "source": [
        "import torch\r\n",
        "import torchvision # provide access to datasets, models, transforms, utils, etc\r\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTmUYY1W98iq"
      },
      "source": [
        "# Step1: Loading EMNIST by class data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "f9add1a4c67c4ce78cf68c86a11f9a0e"
          ]
        },
        "id": "eSaMifqC_E-b",
        "outputId": "65783f99-62ac-480b-aa75-a1a746c58c4f"
      },
      "source": [
        "# now let's work with FashionMnist\r\n",
        "\r\n",
        "train_set = torchvision.datasets.EMNIST(\r\n",
        "    split = 'byclass',\r\n",
        "    root='./data'\r\n",
        "    ,train=True\r\n",
        "    ,download=True\r\n",
        "    ,transform=transforms.Compose([\r\n",
        "        transforms.ToTensor()\r\n",
        "    ])\r\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading and extracting zip archive\n",
            "Downloading http://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip to ./data/EMNIST/raw/emnist.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9add1a4c67c4ce78cf68c86a11f9a0e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/EMNIST/raw/emnist.zip to ./data/EMNIST/raw\n",
            "Processing byclass\n",
            "Processing bymerge\n",
            "Processing balanced\n",
            "Processing letters\n",
            "Processing digits\n",
            "Processing mnist\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlPtgQPpCfbk"
      },
      "source": [
        "#Step2 :Train Loader properties\r\n",
        "1. shuffling the data \r\n",
        "2. setting the batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zdla6NRG_kxR",
        "outputId": "a92ffa51-389e-4095-c4d2-36790577053b"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_set\r\n",
        "    ,batch_size=10\r\n",
        "    ,shuffle=True\r\n",
        ")\r\n",
        "len(train_set)\r\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "697932"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eteo8zQECtgv",
        "outputId": "d7851ad5-39cb-4e5b-bb0a-2e75297f2d6d"
      },
      "source": [
        "from pprint import pprint\r\n",
        "\r\n",
        "pprint(max(train_set.train_labels)) # 0-61 is the label names\r\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(61)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "pm7t-XHdCyfr",
        "outputId": "4af3d25e-55da-4607-b3a1-53e430caf988"
      },
      "source": [
        "train_set.train_labels.bincount() #frequency of each label, we have unbalanced class here\r\n",
        "# Bar graph for number of samples/class\r\n",
        "import matplotlib.pyplot as plt  # This is python's popular plotting library.\r\n",
        "# This is to ensure matplotlib plots inline and does not try to open a new window.\r\n",
        "%matplotlib inline \r\n",
        "# Show the tensor.\r\n",
        "def showTensor(aTensor):\r\n",
        "    plt.figure()\r\n",
        "    plt.bar(range(0,62),aTensor.numpy())\r\n",
        "    plt.show()\r\n",
        "    \r\n",
        "showTensor(train_set.train_labels.bincount());"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZh9dDX2IOg4"
      },
      "source": [
        "# visualizing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "eJePrspVDyyr",
        "outputId": "ff6cd486-72f1-43f9-cdd1-864e2dd206f7"
      },
      "source": [
        "sample = next(iter(train_set))\r\n",
        "image, label = sample\r\n",
        "print(\"image shape:\", image.shape)\r\n",
        "plt.imshow(image.squeeze(), cmap='gray')\r\n",
        "print('label:', label)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image shape: torch.Size([1, 28, 28])\n",
            "label: 35\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke790ZxPJLBH"
      },
      "source": [
        "#Step3: Network Building\r\n",
        "1. 6 Convolution layers with these kernels (10, 10, 20, 20, 30)\r\n",
        "2. no fully connected layer (use of Global Average Pooling layer)\r\n",
        "3. use of EMNIST as the dataset - by_class \r\n",
        "4. use of one max-pooling layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1hnoYonHhaJ"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "class Network(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=3)\r\n",
        "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3)\r\n",
        "        self.conv3 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3)\r\n",
        "        self.conv4 = nn.Conv2d(in_channels=20, out_channels=20, kernel_size=3)\r\n",
        "        self.conv5 = nn.Conv2d(in_channels=20, out_channels=30, kernel_size=3)\r\n",
        "        self.conv6 = nn.Conv2d(in_channels=30, out_channels=62, kernel_size=3)\r\n",
        "\r\n",
        "        #self.Adtap = nn.AdaptiveAvgPool2d(1)\r\n",
        "        self.gap = nn.AvgPool2d(kernel_size=4)\r\n",
        "        \r\n",
        "\r\n",
        "        #self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)\r\n",
        "        #self.fc2 = nn.Linear(in_features=120, out_features=60)\r\n",
        "        #self.out = nn.Linear(in_features=60, out_features=10)\r\n",
        "\r\n",
        "    def forward(self, inputTensor):\r\n",
        "        # (1) input layer\r\n",
        "        t = inputTensor    # input image size = 28*28*1\r\n",
        "\r\n",
        "        # (2) hidden conv layer\r\n",
        "        t = self.conv1(t)  # input size = 28*28*1  output = 26*26*10  RF = 3*3 \r\n",
        "        t = F.relu(t)\r\n",
        "        \r\n",
        "        # (3) hidden conv layer\r\n",
        "        t = self.conv2(t)  # input size = 26*26*10  output = 24*24*10  RF = 5*5 \r\n",
        "        t = F.relu(t)\r\n",
        "        t = F.max_pool2d(t, kernel_size=2, stride=2)  # input size = 24*24*10  output = 12*12*10  RF = 10*10 \r\n",
        "\r\n",
        "\r\n",
        "        # (4) hidden conv layer\r\n",
        "        t = self.conv3(t)  # input size = 12*12*10  output = 10*10*20  RF = 12*12 \r\n",
        "        t = F.relu(t)\r\n",
        "\r\n",
        "        # (5) hidden conv layer\r\n",
        "        t = self.conv4(t)  # input size = 10*10*20  output = 8*8*20  RF = 14*14\r\n",
        "        t = F.relu(t)\r\n",
        "        #t = F.max_pool2d(t, kernel_size=2, stride=2)\r\n",
        "\r\n",
        "        # (6) hidden conv layer\r\n",
        "        t = self.conv5(t)   # input size = 8*8*20  output = 6*6*30  RF = 16*16 \r\n",
        "        t = F.relu(t)\r\n",
        "\r\n",
        "\r\n",
        "        # (7) hidden conv layer\r\n",
        "        t = self.conv6(t)  # input size = 6*6*30  output = 4*4*62  RF = 18*18\r\n",
        "        \r\n",
        "\r\n",
        "        # (8) output layer\r\n",
        "       # t = self.Adtap(t)  # input size = 4*4*62  output = 1*1*62  RF = 28*28\r\n",
        "        t = self.gap(t) #62 converted into 62 outputs\r\n",
        "        t = F.softmax(t.view(-1,62), dim=1)\r\n",
        "\r\n",
        "        return t"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__eCXmKWg26P",
        "outputId": "80ac939b-fac4-4202-cd79-e902cef66f49"
      },
      "source": [
        "# from torchsummary import summary\r\n",
        "# network = Network()\r\n",
        "# summary(network,(1,28,28))\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "device\r\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4Jh6C9C2guE"
      },
      "source": [
        "#Step4: Network Training\r\n",
        "1. network weights/paramters, image,labels are on cuda device\r\n",
        "2. Calculated accuracy for every epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnFa16w3XE_W",
        "outputId": "7f8b5a34-13ec-41a7-c508-5c22710cf2c5"
      },
      "source": [
        "import torch.optim as optim\r\n",
        "network = Network()\r\n",
        "if torch.cuda.is_available():\r\n",
        "    network.cuda()\r\n",
        "\r\n",
        "device = torch.device('cuda:0')\r\n",
        "def get_num_correct(preds, labels):\r\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128)\r\n",
        "optimizer = optim.SGD(network.parameters(), lr=0.01)\r\n",
        "\r\n",
        "for epoch in range(25):\r\n",
        "    total_loss = 0\r\n",
        "    total_correct = 0\r\n",
        "\r\n",
        "    for batch in train_loader: # Get Batch\r\n",
        "        images, labels = batch \r\n",
        "        images, labels = images.to(device),labels.to(device) \r\n",
        "\r\n",
        "        preds = network(images) # Pass Batch        \r\n",
        "        loss = F.cross_entropy(preds, labels) # Calculate Loss\r\n",
        "\r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss.backward() # Calculate Gradients\r\n",
        "        optimizer.step() # Update Weights\r\n",
        "\r\n",
        "        total_loss += loss.item()\r\n",
        "        total_correct += get_num_correct(preds, labels)\r\n",
        "\r\n",
        "    print(\r\n",
        "        \"epoch\", epoch, \r\n",
        "        \"total_correct:\", total_correct, \r\n",
        "        \"loss:\", total_loss,\r\n",
        "        \"acc:\",total_correct/len(train_set)\r\n",
        "    )"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 total_correct: 23404 loss: 22504.437237739563 acc: 0.03353335281947238\n",
            "epoch 1 total_correct: 24631 loss: 22501.673963069916 acc: 0.03529140374706991\n",
            "epoch 2 total_correct: 28612 loss: 22492.879009723663 acc: 0.04099539783245359\n",
            "epoch 3 total_correct: 74330 loss: 22091.18756365776 acc: 0.10650034673865076\n",
            "epoch 4 total_correct: 152923 loss: 21464.921126127243 acc: 0.2191087383871208\n",
            "epoch 5 total_correct: 166093 loss: 21357.218734264374 acc: 0.23797877157086936\n",
            "epoch 6 total_correct: 172575 loss: 21306.159800052643 acc: 0.2472662093155207\n",
            "epoch 7 total_correct: 199520 loss: 21098.12817287445 acc: 0.28587312230990986\n",
            "epoch 8 total_correct: 202130 loss: 21074.611702680588 acc: 0.28961274164245226\n",
            "epoch 9 total_correct: 203175 loss: 21065.29334807396 acc: 0.2911100221798112\n",
            "epoch 10 total_correct: 203926 loss: 21059.07872390747 acc: 0.2921860582406309\n",
            "epoch 11 total_correct: 204529 loss: 21054.0988574028 acc: 0.293050039258839\n",
            "epoch 12 total_correct: 204985 loss: 21050.07965350151 acc: 0.29370339803877743\n",
            "epoch 13 total_correct: 205442 loss: 21046.36334323883 acc: 0.2943581896230578\n",
            "epoch 14 total_correct: 205876 loss: 21043.306891918182 acc: 0.2949800267074729\n",
            "epoch 15 total_correct: 206172 loss: 21040.492921113968 acc: 0.2954041367926961\n",
            "epoch 16 total_correct: 206513 loss: 21037.91206550598 acc: 0.295892723073308\n",
            "epoch 17 total_correct: 206743 loss: 21035.691977262497 acc: 0.29622226807196117\n",
            "epoch 18 total_correct: 220561 loss: 20929.737924814224 acc: 0.31602075846930644\n",
            "epoch 19 total_correct: 237319 loss: 20799.513122558594 acc: 0.3400316936320444\n",
            "epoch 20 total_correct: 238132 loss: 20792.78276872635 acc: 0.34119656356206624\n",
            "epoch 21 total_correct: 238599 loss: 20788.515074968338 acc: 0.34186568318976635\n",
            "epoch 22 total_correct: 238996 loss: 20785.089584589005 acc: 0.3424345065135285\n",
            "epoch 23 total_correct: 239360 loss: 20782.25047302246 acc: 0.3429560472940057\n",
            "epoch 24 total_correct: 239637 loss: 20779.600054502487 acc: 0.3433529340967315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAPIWNhFamC8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}