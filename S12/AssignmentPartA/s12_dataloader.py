# -*- coding: utf-8 -*-
"""S12_DataLoader.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a-0uMivLN6Scje0YpseKkrJZJSJAy6bZ
"""

import torchvision
from torchvision import datasets
from torch.utils.data import DataLoader
import torch
import matplotlib.pyplot as plt
import numpy as np
import albumentations as A
from albumentations.pytorch import ToTensorV2


class MyLazyDataset(torch.utils.data.Dataset):
    def __init__(self, dataset, transform=None):
        self.dataset = dataset
        self.transform = transform

    def __getitem__(self, index):
        if self.transform:
            x = self.transform(self.dataset[index][0])
        else:
            x = self.dataset[index][0]
        y = self.dataset[index][1]
        return x, y

    def __len__(self):
        return len(self.dataset)


class ImageDataLoader(DataLoader):
    """
    Load Image datasets from torch
    Default category is MNIST
    Pass category as 'MNIST' or 'CIFAR10'
    """

    def __init__(self, train_transforms, test_transforms, data_dir, batch_size, shuffle, category='custom',
                 num_workers=4, pin_memory=False, device='cpu',
                 figure_size=(20, 8), test_pct=0.1):
        self.data_dir = data_dir
        self.figure_size = figure_size
        cuda = torch.cuda.is_available()
        self.init_kwargs = {
            'batch_size': batch_size,
            'num_workers': num_workers,
            'pin_memory': pin_memory
        }

        def get_augmentation(transforms):
            return lambda img: transforms(image=np.array(img))['image']

        if cuda:
            self.device = 'gpu'
            pin_memory = True
        else:
            self.device = device

        self.classes = None

        if category == 'MNIST':
            self.train_loader = datasets.MNIST(
                self.data_dir,
                train=True,
                download=True,
                # transform=transforms.build_transforms(train=True)
                transform=get_augmentation(train_transforms)
            )
            self.test_loader = datasets.MNIST(
                self.data_dir,
                train=False,
                download=True,
                # transform=transforms.build_transforms(train=False)
                transform=get_augmentation(test_transforms)
            )
            self.train_loader = DataLoader(self.train_loader, shuffle=shuffle, **self.init_kwargs)
            self.test_loader = DataLoader(self.test_loader, **self.init_kwargs)
        elif category == 'CIFAR10':
            self.train_loader = datasets.CIFAR10(
                self.data_dir,
                train=True,
                download=True,
                transform=get_augmentation(train_transforms)
                # transform=transforms.build_transforms(train=True)
            )
            self.test_loader = datasets.CIFAR10(
                self.data_dir,
                train=False,
                download=True,
                # transform=transforms.build_transforms(train=False)
                transform=get_augmentation(test_transforms)
            )
            self.classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog',
                            'horse', 'ship', 'truck')
            self.train_loader = DataLoader(self.train_loader, shuffle=shuffle, **self.init_kwargs)
            self.test_loader = DataLoader(self.test_loader, **self.init_kwargs)

        elif category == 'custom':
            self.dataset = datasets.ImageFolder(data_dir)
            data_len = len(self.dataset)

            indices = list(range(data_len))
            np.random.shuffle(indices)
            split = int(np.floor(test_pct * data_len))
            train_idx, test_idx = indices[split:], indices[:split]

            train_set = MyLazyDataset(self.dataset, get_augmentation(train_transforms))
            test_set = MyLazyDataset(self.dataset, get_augmentation(test_transforms))

            train_data = torch.utils.data.Subset(train_set, train_idx)
            test_data = torch.utils.data.Subset(test_set, test_idx)

            self.train_loader = torch.utils.data.DataLoader(train_data, shuffle=shuffle, **self.init_kwargs)
            self.test_loader = torch.utils.data.DataLoader(test_data, **self.init_kwargs)

            self.classes = self.dataset.classes

    def show(self, dataset_type='train'):
        if dataset_type == 'train':
            dataiter = iter(self.train_loader)
        else:
            dataiter = iter(self.test_loader)

        images, labels = dataiter.next()
        img = torchvision.utils.make_grid(images)

        img = img / 2 + 0.5  # unnormalize
        npimg = img.numpy()

        plt.figure(figsize=self.figure_size)
        plt.imshow(np.transpose(npimg, (1, 2, 0)))

from torch.utils.data import Dataset
import albumentations as A
from albumentations.pytorch import ToTensorV2
import numpy as np
from torchvision import datasets

class GetItemDataset(Dataset):
    def __init__(self, dataset, transform=None):
        self.dataset = dataset
        self.transform = transform

    def __getitem__(self, index):
        x = self.transform(self.dataset[index][0])
        y = self.dataset[index][1]
        return x, y


    # def __getitem__(self, index):
    #     if self.transform:
    #         x = self.transform(self.dataset[index][0])
    #     else:
    #         x = self.dataset[index][0]
    #     y = self.dataset[index][1]
    #     return x, y

    def __len__(self):
        return len(self.dataset)

class TinyImagenetDataLoader(Dataset):
    
    def __init__(self):
        pass
    def build_transforms(self,  train_tfms_list=[], test_tfms_list=[]):
        train_tfms_list.extend([A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]), ToTensorV2()])
        test_tfms_list.extend([A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]), ToTensorV2()])
        return A.Compose(train_tfms_list), A.Compose(test_tfms_list)

    def get_augmentation(self,transforms):
        return lambda img: transforms(image=np.array(img))['image']
                
    def tinyImgnetDataWithAugmentation(self,DIRPATH, input_batch_size, input_num_workers =2, test_Partition = 0.1,cust_train_tfms_list=[], cust_test_tfms_list=[]):

        self.dataset = datasets.ImageFolder(DIRPATH)
        data_len = len(self.dataset)

        indices = list(range(data_len))
        np.random.shuffle(indices)
        split = int(np.floor(test_Partition * data_len))
        train_idx, test_idx = indices[split:], indices[:split]

        train_transform1,  test_transform1 = self.build_transforms(train_tfms_list=cust_train_tfms_list, test_tfms_list=cust_test_tfms_list)

        trainset = GetItemDataset(self.dataset, self.get_augmentation(train_transform1))
        testset = GetItemDataset(self.dataset, self.get_augmentation(test_transform1))

        train_data = torch.utils.data.Subset(trainset, train_idx)
        test_data = torch.utils.data.Subset(testset, test_idx)

        trainloader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size = input_batch_size, num_workers = input_num_workers)
        testloader = torch.utils.data.DataLoader(test_data,shuffle=False, batch_size = input_batch_size, num_workers = input_num_workers)

        classes = self.dataset.classes        
        return trainset, trainloader, testset, testloader, classes

from torch.utils.data import Dataset
import albumentations as A
from albumentations.pytorch import ToTensorV2
import numpy as np
#from torchvision import datasets


class AlbumentationsDataset(Dataset):
        
    def __init__(self):
            pass
    def build_transforms(self,  train_tfms_list=[], test_tfms_list=[]):
            train_tfms_list.extend([A.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]), ToTensorV2()])
            test_tfms_list.extend([A.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]), ToTensorV2()])
            return A.Compose(train_tfms_list), A.Compose(test_tfms_list)

    def get_augmentation (self,transforms):
                return lambda img: transforms(image=np.array(img))['image']

    def cifar10dataWithAugmentation(self,input_batch_size,cust_train_tfms_list=[], cust_test_tfms_list=[]):
        #Aclass = AlbumentationsDataset()
        # custom_train_tfms = [ A.RandomCrop(32, 32, p=0.8),
        #                     A.HorizontalFlip()]
        train_transform1,  test_transform1 = self.build_transforms(train_tfms_list=cust_train_tfms_list, test_tfms_list=cust_test_tfms_list)

        #print(train_transform1)

        trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform = self.get_augmentation(train_transform1))
        trainloader = torch.utils.data.DataLoader(trainset, batch_size=input_batch_size,
                                                shuffle=True, num_workers=2)

        testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                            download=True, transform=self.get_augmentation(test_transform1))
        testloader = torch.utils.data.DataLoader(testset, batch_size=input_batch_size,
                                                shuffle=False, num_workers=2)
        classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog','horse', 'ship', 'truck')
        return trainset, trainloader, testset, testloader, classes

import torchvision
import torchvision.transforms as transforms
import torch

def CIFAR10DataLoader(input_batch_size):
    transform = transforms.Compose(
        [transforms.ToTensor(),
         # transforms.RandomRotation((-15.0, 15.0), fill=(1,)),
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                            download=True, transform=transform)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=input_batch_size,
                                              shuffle=True, num_workers=2)

    testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                           download=True, transform=transform)
    testloader = torch.utils.data.DataLoader(testset, batch_size=input_batch_size,
                                             shuffle=False, num_workers=2)

    classes = ('plane', 'car', 'bird', 'cat',
               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
    return trainset, trainloader, testset, testloader, classes

def CIFAR10Check_Mean_STD(input_batch_size):
        
    transform = transforms.Compose(
        [transforms.ToTensor()])

    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                            download=True, transform=transform)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=input_batch_size,
                                                shuffle=True, num_workers=2)
    mean = 0.0
    std = 0.0
    nb_samples = 0.
    for data, C in trainloader:
        #data = images
        #print(data)
        batch_samples = data.size(0)
        # print(batch_samples)
        # print(data.size(1))
        # print(data.size(2))  
        data = data.view(batch_samples, data.size(1), -1) # data dimension = batchsize * number of channels * (h*w) = 128*3*(32*32) 
        # print(data.size(2))
        # print(type(data))
        # m = data.mean(2).sum(0)
        # print(m)
        # break
        mean += data.mean(2).sum(0) # summing for each image in a batch which gives 128*1024 values
        # mean(2) : mean of the 1024 values corresponds to the 1 channel of the image, sum(0): sum of whole batch images 
        std += data.std(2).sum(0)
        nb_samples += batch_samples

    # print('mean', mean)
    # print('std', std)
    # print('nb_samples', nb_samples)
    mean /= nb_samples
    std /= nb_samples
    return mean, std

def CIFAR10DataLoaderWithRotate(input_batch_size):
    transform_train = transforms.Compose(
        [transforms.ToTensor(),
         transforms.RandomRotation((-7.0, 7.0), fill=(1,)),
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                            download=True, transform=transform_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=input_batch_size,
                                              shuffle=True, num_workers=2)

    transform_test = transforms.Compose(
        [transforms.ToTensor(),
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
    testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                           download=True, transform=transform_test)
    testloader = torch.utils.data.DataLoader(testset, batch_size=input_batch_size,
                                             shuffle=False, num_workers=2)

    classes = ('plane', 'car', 'bird', 'cat',
               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
    return trainset, trainloader, testset, testloader, classes

def CIFAR10DataLoaderWithRotateCrop(input_batch_size):
    transform_train = transforms.Compose(
        [transforms.ToTensor(),
         transforms.CenterCrop(30),
         transforms.RandomRotation((-7.0, 7.0), fill=(1,)),
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                            download=True, transform=transform_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=input_batch_size,
                                              shuffle=True, num_workers=2)

    transform_test = transforms.Compose(
        [transforms.ToTensor(),
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
    testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                           download=True, transform=transform_test)
    testloader = torch.utils.data.DataLoader(testset, batch_size=input_batch_size,
                                             shuffle=False, num_workers=2)

    classes = ('plane', 'car', 'bird', 'cat',
               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
    return trainset, trainloader, testset, testloader, classes

def CIFAR10DataLoaderWithRotateNormalization(input_batch_size, mean, std):
    #print(tuple(mean), tuple(std))
    transform_train = transforms.Compose(
        [transforms.ToTensor(),
         transforms.RandomRotation((-7.0, 7.0), fill=(1,)),
         transforms.Normalize(mean, std)])

    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                            download=True, transform=transform_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=input_batch_size,
                                              shuffle=True, num_workers=2)

    transform_test = transforms.Compose(
        [transforms.ToTensor(),
         transforms.Normalize(mean, std)])
    testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                           download=True, transform=transform_test)
    testloader = torch.utils.data.DataLoader(testset, batch_size=input_batch_size,
                                             shuffle=False, num_workers=2)

    classes = ('plane', 'car', 'bird', 'cat',
               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
    return trainset, trainloader, testset, testloader, classes

def CIFAR10DataLoaderWithRotateNormalizationwithConstantValues(input_batch_size):
    #print(tuple(mean), tuple(std))
    transform_train = transforms.Compose(
        [transforms.ToTensor(),
         transforms.RandomRotation((-7.0, 7.0), fill=(1,)),
         transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])

    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                            download=True, transform=transform_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=input_batch_size,
                                              shuffle=True, num_workers=2)

    transform_test = transforms.Compose(
        [transforms.ToTensor(),
         transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])
    testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                           download=True, transform=transform_test)
    testloader = torch.utils.data.DataLoader(testset, batch_size=input_batch_size,
                                             shuffle=False, num_workers=2)

    classes = ('plane', 'car', 'bird', 'cat',
               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
    return trainset, trainloader, testset, testloader, classes