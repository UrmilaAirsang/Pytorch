# -*- coding: utf-8 -*-
"""S9_MainFile_CIFAR10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mpfMNKEWmcP4G6_d91dnWK0x8Tl5p1FG

#Creating Seperate files

1. Added albumentation data augmentation method in data loader file
2. Implemented gradcam in a seperate file 


##Achieved : **87.71%** using Resnet18 model with Albumentation 

Remarks:
Learnings:
1. How to incorporate albumentation in pytorch dataloader
2. Gradcam implementation and working

After 14 epochs model started to saturate and lead to overfitting. This can be avois=ded further by using regularizations and different image augmentation techniques
"""

! pip install albumentations==0.4.6

from google.colab import drive
drive.mount('/content/drive', force_remount= True)

import sys
import os
sys.path.append('/content/gdrive/')
py_file_location = "/content/drive/My Drive/S9_CIFAR10_Albumentation/"
sys.path.append(os.path.abspath(py_file_location))

# Commented out IPython magic to ensure Python compatibility.
# %cd '/content/drive/My Drive/S9_CIFAR10_Albumentation'
!pwd
!ls

# Import your module or file
from s9_cifar_modelfile import Net, ResNet18
from s9_cifar_dataloader import AlbumentationsDataset
from s9_train_file import train
from s9_test_file import test
from s9_gradcam import GradCam

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import torch
import torchvision
import torchvision.transforms as transforms

SEED = 1
# CUDA?
cuda = torch.cuda.is_available()
print("CUDA Available?", cuda)

# For reproducibility
torch.manual_seed(SEED)

if cuda:
    torch.cuda.manual_seed(SEED)

"""##------------------------Call to Data Loader-------------------------

Use of Albumentation method for data augmentation
"""

import albumentations as A
aclass = AlbumentationsDataset()
input_batch_size =128

custom_train_tfms = [ A.RandomCrop(32, 32, p=0.8),
                    A.HorizontalFlip()]
trainset, trainloader, testset, testloader, classes = aclass.cifar10dataWithAugmentation(input_batch_size, custom_train_tfms)

"""##------------------ Visualize Input Image ---------------------------- 

---



---


Let us show some of the training images, for fun.

"""

import matplotlib.pyplot as plt
import numpy as np
import cv2
# functions to show an image
def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy() 
    plt.imshow(np.transpose(npimg, (1, 2, 0)))

# # get some random training images
dataiter = iter(trainloader)
images, labels =  dataiter.next()
print(images.numpy().shape)  

plt.figure(figsize=(20,10))
# show images
imshow(torchvision.utils.make_grid(images))

"""##  ------------------------------Getting Resnet18 network from model file----------------------- 

1. Get the model
2. print summary
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Copy the neural network from the Neural Networks section before and modify it to
take 3-channel images (instead of 1-channel images as it was defined).


"""

# load to device and print model summary
!pip install torchsummary
from torchsummary import summary
use_cuda = torch.cuda.is_available()
device = torch.device("cuda" if use_cuda else "cpu")
print(device)
# call now Resnet18 model
model = ResNet18().to(device)
summary(model, input_size=(3, 32, 32))

"""##------------------------------Calling training and testing  -------------------------"""

import torch.optim as optim
from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau
import torch.nn as nn
import torch.nn.functional as F

criterion = nn.CrossEntropyLoss()
model =  ResNet18().to(device)
# without weight reached 80%
# with weight = 0 reached 79%
#with weight = 0.5 reached  Test accuracy = 10%
optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.7 )

scheduler = StepLR(optimizer, step_size=10, gamma=0.1)

EPOCHS = 25
for epoch in range(EPOCHS):
    #print("EPOCH:", epoch)
    print('Epoch-{0} lr: {1}'.format(epoch, optimizer.param_groups[0]['lr']))
    train(model, device, trainloader, optimizer, epoch,criterion)
    scheduler.step()
    test(model, device, testloader)

"""5. Test the network on the test data
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^



"""

dataiter = iter(testloader)
images, labels = dataiter.next()
images, labels = images.to(device), labels.to(device)

imagesToshow = images.detach().cpu()
# print images
imshow(torchvision.utils.make_grid(imagesToshow))
print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))

def classwiseAccuracy(model,device,testloader, batchSize,numClasses):
  class_correct = list(0. for i in range(numClasses))
  class_total = list(0. for i in range(numClasses))
  with torch.no_grad():
      for data in testloader:
          images, labels = data
          images, labels = images.to(device), labels.to(device)
          outputs = model(images)
          _, predicted = torch.max(outputs, 1)
          c = (predicted == labels).squeeze()
          for i in range(batchSize):
              label = labels[i]
              class_correct[label] += c[i].item()
              class_total[label] += 1
  for i in range(numClasses):
        print('Accuracy of %5s : %2d %%' % (
            classes[i], 100 * class_correct[i] / class_total[i]))

classwiseAccuracy(model, device, testloader,4,10)

#from gradcam import GradCam
img_tensor_batch, labels = next(iter(testloader))
for idx in range(10):
  gm = GradCam(model=model, img_tensor=img_tensor_batch[idx],
              correct_class=labels[idx], classes=classes,
              feature_module=model.layer4, target_layer_names=['1'])
  gm.visualize()

